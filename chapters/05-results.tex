\chapter{Evaluation}\label{ch:results}

The resulting transformation is able to handle programs where only integer
arithmetic is abstracted. We provide ability for pointers to point to the
abstract values and structures to contain abstract elements. However we are
currently not able to insert abstract values into arrays, represent abstract
pointers and do a dynamic memory allocation of abstract values. These
limitations are caused by insufficient representation of abstract data, in the
case of arrays\sidenote{Currently, we are not able to represent elements of
arrays by shapes for abstract values. We think this can easily implemented in a
similar manner as abstraction of aggregate types. Further limitations represent
a runtime indices into the arrays, which we are not able to compute during
transformation.}, and missing pointer analysis in the case of pointers. For
further evaluation we have omitted programs that contain these unsupported
characteristics.

Other technicalities, such as support of threading and support of full \Cpp{}
standard library remains untouched, since transformations do not interfere with
explicit computation of a program.

To show that the proposed approach is sufficient replacement of \SymDIVINE, we
will compare the symbolic transformation with \DIVINE as backend against
\SymDIVINE. Evaluation will be done on the subset of benchmarks from software
verification competition (\svcomp)~\cite{Beyer17}.
And to prove the capabilities of transformation we will benchmark the
verification of basic data structures, concretely binary trees and more
complicated \AVL tree. The \AVL tree benchmarks demonstrate the ability of
transformation of more complicated code.

All measurements were done on \dots
\add{add description of machine ? }

\section{\textsc{sv-comp} benchmarks}

From \svcomp benchmarks we have chosen only those benchmarks that contain
nondeterminism on integers. Rules of \svcomp define a set of intrinsics for
verification tool, such as assume, assert and nondeterministic
input~\cite{svcomp}. We have implemented these intrinsics using the annotations.
For example, implementation of \code{\_\_VERIFIER\_nondet\_int()} is following:

\begin{minted}{cpp}
int __VERIFIER_nondet_int() {
    _SYM int value;
    return value;
}
\end{minted}
Further specification of intrinsics can be found in \autoref{ch:appendixb} or in
the competition rules~\cite{svcomp}.

All benchmarks are included in the archive of this thesis. They are further
partitioned into following categories:
\begin{itemize}
    \item \textbf{pthreads}: programs that contain parallelism.
    \item \textbf{loops}: programs with loops that depends on input value.
    \item \textbf{recursion}: recursive programs taking an arbitrary input.
    \item \textbf{bitvector}: programs that make complex binary operations.
    \item \textbf{product-lines}: generated program modeling products, such as
        elevator.
\end{itemize}

With benchmarks we want to show, what are we able to transform and verify with \DIVINE in comparison to
\SymDIVINE. We have measured how many benchmarks we were able to correctly
verify in a timeframe of 15 minutes (as in \svcomp).

In \autoref{tbl:results} we summarize each category for both tools. We count how
many programs were correctly proved to be valid (\textbf{valid}), in how
many benchmarks we have found a reachable error (\textbf{error}), number of
timeouts (\textbf{timeout}) and number of failed verifications, either caused by
error during the verification or reporting a wrong result (\textbf{failed}).

\begin{table}
\checkoddpage
\edef\side{\ifoddpage l\else r\fi}
\makebox[\textwidth][\side]{
\begin{minipage}[bt]{\fullwidth}
  \begin{center}
    \setlength{\tabcolsep}{0.5em}
    \begin{tabularx}{\textwidth}{l r r r r r X r r r r}
      \toprule
      & ~ & \multicolumn{4}{c}{\DIVINE + transformation} & ~ & \multicolumn{4}{c}{\SymDIVINE} \\
      \cmidrule(l){3-6}
      \cmidrule(l){8-11}
      & & valid & error & timeout & failed & & valid & error & timeout & failed \\
      \midrule
      pthreads &        & $0$ & $0$ & $0$ & $0$ &   & $0$ & $0$ & $0$ & $0$  \\
      loops &           & $1$ & $15$ & $13$ & $2$ & & $7$ & $11$ & $12$ & $1$  \\
      recursion &       & $4$ & $14$ & $22$ & $0$ & & $2$ & $11$ & $27$ & $0$  \\
      bitvector &       & $7$ & $1$ & $24$ & $12$ & & $6$ & $3$ & $35$ & $0$  \\
      product-lines &   & $0$ & $0$ & $0$ & $0$ &   & $0$ & $0$ & $0$ & $0$  \\
      \midrule
      \midrule
      overall &         & $12$ & $30$ & $59$ & $14$ &   & $15$ & $25$ & $74$ & $1$  \\
      \bottomrule
    \end{tabularx}
  \end{center}
    \caption{Comparison of \DIVINE and \SymDIVINE on \svcomp benchmarks.}
  \label{tbl:results}
\end{minipage}}
\end{table}

In all benchmarks the transformation successfully finishes in a order of
seconds. But differences between tools have shown during the verification.
Surprisingly \SymDIVINE competes with \DIVINE quite well. Why is it so?

Even though \DIVINE utilize a $\tau$-reduction and faster \LLVM interpreter the
bottleneck of verification is in interface with an \SMT solver. For each \SMT
query \DIVINE spawns a new process with a solver, and that requires nontrivial
amount of time. Also a computation with the solver is done ineffectively via a string stream.

In \SymDIVINE, the process with solver is maintained during the entire verification,
hence it saves a time of process creation. Moreover, the communication with solver
is treated by a dedicated interface, which is faster. Additionally, \SymDIVINE
utilize a caching of queries.

Hence, \SymDIVINE can explore a state-space much more faster (around 200 states
per second), but it encounters larger state spaces, because of missing state
space reduction techniques. On the other hand, \DIVINE proceeds slower (10
states per second), but profits from smaller state spaces.

In the results, we can see that \DIVINE failed in a few cases. Fails in
bitvector category were caused by some error in the \DIVINE. Fails in loop
category were caused by a false positive result. In this case, we presume that
an implementation of symbolic domain contains a bug.

\add{ add qunatitative plot of benchmarks }

\add{ add description of plots }

\section{Data structures}

The data structure benchmarks show the greatest contribution of a symbolic
approach. By symbolic representation of elements in data structures we can
verify all possible behaviours for given amount of inputs. In these benchmarks
we will demonstrate how much time the transformation takes and how much time
\DIVINE spends in verification process. Because these benchmarks are in \Cpp, we
can not compare results with \SymDIVINE.

In all benchmarks we will try to verify insertions and deletions of arbitrary
values from the data structures. The data structures will be stored on the
stack, because we are limited in transformation by dynamic memory allocation.
We set naming convention for benchmarks as \code{\{name\}-\{num. of
insertion\}-\{num. of deletions\}-\{V/E for validity or error\}}.

\begin{table}
  \begin{center}
    \begin{tabularx}{\textwidth}{l r r r}
      \toprule
      Benchmark Name & Transformation & Verification & States \\
        \midrule
        \code{sorted-list-3-0-E} & $8.52s$ & $0.02s$ & $14$ \\
        \code{sorted-list-3-0-V} & $10s$ & $37s$ & $39$ \\
        \code{sorted-list-4-0-V} & $11.6s$ & $2m 14s$ & $155$ \\
        \code{sorted-list-5-0-V} & $9.04s$ & $8m 15s$ & $733$ \\
        \midrule

        \code{bintree-3-0-V} & $9.81s$ & $33.3s$ & $78$ \\
        \code{bintree-3-1-V} & $12.3s$ & $33.9s$ & $124$ \\
        \code{bintree-3-2-V} & $13s$ & $27s$ & $171$ \\
        \code{bintree-3-3-V} & $12.1s$ & $16s$ & $192$ \\

        \midrule

        \code{avl-1-0-V} & $6.15s$ & $1.93s$ & $16$ \\
        \code{avl-2-0-V} & $7.19s$ & $8.31s$ & $64$ \\
        \code{avl-3-0-V} & $7.96s$ & $39s$ & $346$ \\
        \code{avl-4-0-V} & $7.29s$ & $3m~27s$ & $1464$ \\
        \code{avl-5-0-V} & $6.89s$ & $14m~16s$ & $9242$ \\
      \bottomrule
    \end{tabularx}
  \end{center}
  \caption{Benchmarks of insertions and deletions from the data
    structures. A~name of benchmark represents a data structure, number of
    insertions and number of deletions. \code{V} or \code{E} at the end of
    name denotes whether the benchmark is valid or contains error.}
\end{table}

From the results we can see that bottleneck is still a verification. Although,
we have destroyed the data nondeterminism, we have brought a control flow
nondeterminism because of nondeterministic choices on branches. The transformation
time is steadily around 10seconds. An average speed of verification is 2 states
per second. We believe that this is consequence of slow \API between the model
checker and the \SMT solver. Since \SymDIVINE was able to generate 200 states
per seconds in average, with much less optimized exploration algorithm. Hence we
believe that in future we can optimize the algorithm to cope with larger state
spaces in reasonable time.

In benchmarks of the \AVL tree, we can see that despite the increasing number of inputs
the transformation time stays the same, but the verification time exponentially
grows. The exponential growth is caused by the nature of the \AVL tree. When we
are inserting an arbitrary value we have to branch the state space on each
comparison of the inserted value and node into which we are inserting. Branching
creates two possibilities, first when the value is inserted into the left
subtree and second for the right subtree. This way, we create during
verification all possible shapes of the \AVL tree for given amount of elements.
A similar phenomenon appears in other data structures, where the algorithm branches
depending on the inserted value.

But since the algorithms on these data structures are simple, the most of errors
are shallow and can be found much more faster than proving of correctness of
the algorithms.

During the evaluation we have encountered the qualities of the proposed
approach, because besides the verification of the program we have verified the
implementation of the abstraction and fix minor bugs that we have found. This
would not be possible if the abstraction would be implemented inside of the
verification tool.
